# -*- coding: utf-8 -*-

import os
import time
import pandas as pd
from queue import Queue
from threading import Thread, Lock
from dotenv import load_dotenv
from groq import Groq

start_time = time.time()

# API í‚¤ ë¡œë”©
load_dotenv()
api_keys = [
    os.getenv("API_KEY_1"),
    os.getenv("API_KEY_2"),
    os.getenv("API_KEY_3"),
    os.getenv("API_KEY_4"),
]

clients = [Groq(api_key=k) for k in api_keys]

model_list = [
    "deepseek-r1-distill-llama-70b",
    "deepseek-r1-distill-qwen-32b",
    "gemma2-9b-it",
    "llama-3.1-8b-instant",
    "llama-3.2-11b-vision-preview",
    "llama-3.2-1b-preview",
    "llama-3.2-3b-preview",
    "llama-3.2-90b-vision-preview",
    "llama-3.3-70b-specdec",
    "llama-3.3-70b-versatile",
    "llama3-70b-8192",
    "llama3-8b-8192",
    "mistral-saba-24b",
    "qwen-2.5-32b",
    "qwen-2.5-coder-32b",
    "qwen-qwq-32b"
]

# íƒœê·¸ ëª©ë¡
raw_tag_list = """íŒíƒ€ì§€
SF
ë¯¸ìŠ¤í„°ë¦¬
ìŠ¤ë¦´ëŸ¬
ê³µí¬
ë¡œë§¨ìŠ¤
ì—­ì‚¬ì†Œì„¤
ëª¨í—˜
ì½”ë¯¸ë””
ë“œë¼ë§ˆ
ê°ë™ì ì¸
ì”ì”í•œ
ê¸´ì¥ê° ìˆëŠ”
ìš°ìš¸í•œ
ìœ ë¨¸ëŸ¬ìŠ¤í•œ
ì–´ë‘ìš´
ë°ê³  ê¸ì •ì 
ì² í•™ì 
ì—­ë™ì ì¸
ëª½í™˜ì ì¸
ì—­ì„¤ì ì¸
ì”í˜¹í•œ
í™©í™€í•œ
ë¶ˆì•ˆê°ì„ ì¡°ì„±í•˜ëŠ”
ì‚¬íšŒ ë¹„íŒì 
ë¶ˆí‰ë“±
ì  ë” ë¬¸ì œ
ì „ìŸê³¼ í‰í™”
ìš´ëª…ê³¼ ììœ ì˜ì§€
ë„ë•ì  ë”œë ˆë§ˆ
í˜ëª…ê³¼ ì €í•­
í™˜ê²½ê³¼ ìƒíƒœ
ì˜ë£Œ ë° ë°”ì´ì˜¤í…Œí¬
ì™¸êµì™€ ì •ì¹˜ ìŒëª¨
ê¶Œë ¥ê³¼ ë¶€íŒ¨
ë…¸ë™ê³¼ ê³„ê¸‰íˆ¬ìŸ
ì´ë¯¼ê³¼ ì •ì²´ì„±
ë¬¸í™” ì¶©ëŒ
ë¬´ì •ë¶€ì£¼ì˜
ì „í†µê³¼ í˜ì‹ 
ì¸ê³µì§€ëŠ¥ê³¼ ì •ë³´í™”
ì„±ì¥ ì´ì•¼ê¸°
íŠ¸ë¼ìš°ë§ˆì™€ ì¹˜ìœ 
ìš°ì •ê³¼ ë™ë£Œì• 
ì¢…êµì Â·ì˜ì  ìš”ì†Œ
ë³µìˆ˜ì™€ ì •ì˜
ì •ì²´ì„± íƒìƒ‰
ë‚´ë©´ íƒêµ¬
ê¸°ì–µê³¼ ì‹œê°„
ì´ì¤‘ì„±
ê¸ˆê¸°ì™€ ë°˜í•­
ìƒëª…ê³¼ ì£½ìŒ
ìš•ë§ê³¼ íƒ€ë½
ì¬ë‚œÂ·ì„œë°”ì´ë²Œ
ì˜ì‹ì˜ íë¦„
ë¯¸ì™„ì˜ ì´ì•¼ê¸°
ì‹¤í—˜ì  ë¬¸ì²´
í˜•ì‹ íŒŒê´´ì 
ë…íŠ¹í•œ ì„œìˆ  ë°©ì‹
ë””ìŠ¤í† í”¼ì•„
ìœ í† í”¼ì•„
í¬ìŠ¤íŠ¸ ì•„í¬ì¹¼ë¦½ìŠ¤
ì‚¬ì´ë²„í‘í¬
ë‹¤ì¤‘ ìš°ì£¼
ì‹œê°„ ì—¬í–‰
ì´ˆí˜„ì‹¤ì  ê³µê°„
ë¯¸ì§€ì˜ ì˜ì—­ íƒí—˜
ì´ì„¸ê³„
ì‹ í™”ì  ì„¸ê³„
ê°€ìƒ í˜„ì‹¤
ê¸°í›„ ë³€í™” ì„¸ê³„"""

tag_candidates = [t.strip() for t in raw_tag_list.strip().splitlines() if t.strip()]

def generate_prompt(review_text):
    prompt = """
    ë‹¹ì‹ ì€ ë¬¸í•™ ì„œí‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì„œí‰ì„ ì½ê³ , ì œê³µëœ íƒœê·¸ ëª©ë¡ ì¤‘ ì´ ì±…ì— ì–´ìš¸ë¦¬ëŠ” íƒœê·¸ë¥¼ 3ê°œì—ì„œ 5ê°œê¹Œì§€ ê³¨ë¼ì£¼ì„¸ìš”. ë¬´ì¡°ê±´ ê³¨ë¼ì•¼í•©ë‹ˆë‹¤.

    ì¡°ê±´:
    - ì„¤ëª… ì—†ì´ íƒœê·¸ë§Œ í•œ ì¤„ë¡œ ì¶œë ¥
    - ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„ëœ íƒœê·¸ë¥¼ ì¶œë ¥
    - íƒœê·¸ëŠ” ë°˜ë“œì‹œ ëª©ë¡ ì¤‘ì—ì„œ ì„ íƒ
    - ë°˜ë“œì‹œ 3ê°œ ì´ìƒ ì¶œë ¥í•  ê²ƒ
    """
    return f"{prompt}\n\nì„œí‰:\n{review_text}\n\níƒœê·¸ ëª©ë¡:\n{raw_tag_list}"

def extract_valid_tags(text):
    raw_tags = [tag.strip() for tag in text.split(",") if tag.strip()]
    return [tag for tag in raw_tags if tag in tag_candidates]

results = {}
token_cooldown = {}
all_combos = [(m, i) for m in model_list for i in range(len(clients))]
combo_index = 0
combo_lock = Lock()
processed_isbns_lock = Lock()
task_queue = Queue()

tagged_file = "revise_book_test_tagged.csv"
if os.path.exists(tagged_file):
    existing_df = pd.read_csv(tagged_file)
    processed_isbns = set(existing_df["isbn"].dropna().astype(str).tolist())
else:
    existing_df = pd.DataFrame(columns=["isbn", "AI_íƒœê·¸"])
    processed_isbns = set()

max_retries = 5

def model_worker():
    global combo_index
    while True:
        item = task_queue.get()
        if item is None:
            break

        idx, isbn, title, review_text, retry_count = item

        with processed_isbns_lock:
            if isbn in processed_isbns:
                task_queue.task_done()
                continue

        if len(review_text.strip()) <= 100:
            tag_str = ""
            print(f"â„¹ï¸ [{idx+1}] {title} â†’ ë¦¬ë·° ì§§ìŒ, íƒœê·¸ ìƒëµ")
            new_row = pd.DataFrame([{"isbn": isbn, "AI_íƒœê·¸": tag_str}])
            write_header = not os.path.exists(tagged_file) or os.path.getsize(tagged_file) == 0
            new_row.to_csv(tagged_file, mode="a", header=write_header, index=False, encoding="utf-8-sig")
            with processed_isbns_lock:
                processed_isbns.add(isbn)
            print(f"ğŸ“Œ ì €ì¥ëœ ISBN: {isbn} / íƒœê·¸: (ìƒëµ)")
            task_queue.task_done()
            continue

        with combo_lock:
            combo = all_combos[combo_index % len(all_combos)]
            combo_index += 1

        model, client_idx = combo
        client = clients[client_idx]
        cooldown_key = (model, client_idx)

        now = time.time()
        last_used = token_cooldown.get(cooldown_key, 0)
        wait_time = max(0, 4 - (now - last_used))
        if wait_time > 0:
            time.sleep(wait_time)

        prompt = generate_prompt(review_text)
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ë¬¸í•™ ì „ë¬¸ê°€ë¡œì„œ í•œêµ­ì–´ë¡œ ë‹µí•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt},
                ],
                temperature=0.2,
                max_completion_tokens=300,
                top_p=1,
                stream=False,
                timeout=10
            )
            token_cooldown[cooldown_key] = time.time()
            content = response.choices[0].message.content.strip()
            tags = extract_valid_tags(content)

            if len(tags) < 3:
                print(f"âš ï¸ [{idx+1}] {title} â†’ íƒœê·¸ ë¶€ì¡± â†’ ì¬ì‹œë„ {retry_count+1}/{max_retries}")
                if retry_count + 1 < max_retries:
                    task_queue.put((idx, isbn, title, review_text, retry_count+1))
                else:
                    tag_str = "ì˜¤ë¥˜"
                    new_row = pd.DataFrame([{"isbn": isbn, "AI_íƒœê·¸": tag_str}])
                    write_header = not os.path.exists(tagged_file) or os.path.getsize(tagged_file) == 0
                    new_row.to_csv(tagged_file, mode="a", header=write_header, index=False, encoding="utf-8-sig")
                    with processed_isbns_lock:
                        processed_isbns.add(isbn)
                    print(f"ğŸ“Œ ì €ì¥ëœ ISBN: {isbn} / íƒœê·¸: ì˜¤ë¥˜")
            else:
                tag_str = ", ".join(tags)
                print(f"âœ… [{idx+1}] {title} â†’ {tags} ({model}, API_KEY_{client_idx+1})")
                new_row = pd.DataFrame([{"isbn": isbn, "AI_íƒœê·¸": tag_str}])
                write_header = not os.path.exists(tagged_file) or os.path.getsize(tagged_file) == 0
                new_row.to_csv(tagged_file, mode="a", header=write_header, index=False, encoding="utf-8-sig")
                with processed_isbns_lock:
                    processed_isbns.add(isbn)
                print(f"ğŸ“Œ ì €ì¥ëœ ISBN: {isbn} / íƒœê·¸: {tag_str}")

        except Exception as e:
            print(f"âŒ [{idx+1}] {title} ì—ëŸ¬: {e} (API_KEY_{client_idx+1})")
            if retry_count + 1 < max_retries:
                task_queue.put((idx, isbn, title, review_text, retry_count+1))

        task_queue.task_done()

# CSV ë¡œë“œ ë° ì»¬ëŸ¼ ì†Œë¬¸ìí™”
df = pd.read_csv("yes24_steadyseller.csv", on_bad_lines='skip', encoding="utf-8")
df.columns = [col.lower() for col in df.columns]

# íƒœìŠ¤í¬ íì— ì‘ì—… ë„£ê¸°
for idx, row in df.iterrows():
    isbn = str(row.get("isbn", "")).strip()
    if not isbn or isbn.lower() == "nan" or isbn in processed_isbns:
        continue
    title = row.get("title", "")
    review = str(row.get("publisher_review", "")).strip()
    task_queue.put((idx, isbn, title, review, 0))

# ì“°ë ˆë“œ ì‹¤í–‰
threads = []
num_threads = len(model_list) * len(clients) // 2
for _ in range(num_threads):
    t = Thread(target=model_worker)
    t.start()
    threads.append(t)

# ì‘ì—… ëŒ€ê¸°
task_queue.join()
for _ in threads:
    task_queue.put(None)
for t in threads:
    t.join()

end_time = time.time()
print(f"\nâœ… ì„œí‰ íƒœê·¸ ì¶”ì¶œ ì™„ë£Œ â†’ '{tagged_file}'ì— ì €ì¥ë¨!")
print(f"â±ï¸ ì „ì²´ ì†Œìš” ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")


'''

ë¬¸ì œ ìƒí™©

# ë¬¸ì œ 1 : ì„œí‰ ë°ì´í„° ì—†ì–´ë„ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¡œ íƒœê¹… ì§„í–‰

>> í•´ê²° ë°©ë²• ì„œí‰ ë°ì´í„° ê¸¸ì´ 10ì´í•˜ë©´ ê³µë°± ì €ì¥í•˜ê³  ë„˜ì–´ê°
>> ê³µë°±, N/A ë“±ë“± í¬ê´„ì ìœ¼ë¡œ ì²˜ë¦¬ 

# ë¬¸ì œ 2 : í•˜ë‚˜ì— ëŒ€í•´ì„œ ì—¬ëŸ¬ ìŠ¤ë ˆë“œê°€ ì²˜ë¦¬ Ex) 9788959062249 
processed_isbnsëŠ” ì‹¤í–‰ ì‹œì‘ ì‹œì—ë§Œ í•œ ë²ˆ ë§Œë“¤ì–´ì§.
íƒœê·¸ ì¶”ì¶œ ê²°ê³¼(book_test_tagged.csv)ë¥¼ ì €ì¥í•  ë•Œ, ì¤‘ë³µ ISBN ì²´í¬ë¥¼ í•˜ì§€ ì•ŠìŒ.
íŠ¹íˆ ì¬ì‹œë„ ë¡œì§ì´ ìˆê³ , íƒœê·¸ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ë‹¤ì‹œ task_queueì— ë„£ëŠ”ë°, ì´ ê³¼ì •ì—ì„œ ì´ì „ ê²°ê³¼ì™€ í•¨ê»˜ ì¤‘ë³µ ì €ì¥ë  ìˆ˜ ìˆìŒ.

# ì²˜ìŒ ìƒê°
1. ê²°ê³¼ ì €ì¥ ì „ processed_isbnsì— ISBN ì¶”ê°€
ë¬¸ì œì  -> ì‹¤íŒ¨í•œ ISBNë„ 'ì²˜ë¦¬ëœ ê²ƒ'ìœ¼ë¡œ ê°„ì£¼ â†’ ê·¸ë˜ì„œ ì¬ì‹œë„ë„ ì•ˆ ë˜ê³ , ê²°ê³¼ë„ ì—†ëŠ” ìƒíƒœë¡œ ëˆ„ë½

2(ìµœì¢…ì¢…). ìƒí™©ë³„ë¡œ processed_isbns.add(isbn)ì˜ ìœ„ì¹˜ë¥¼ ë¶„ë¦¬
-> ìƒëµ ì¼€ì´ìŠ¤(ì„œí‰ ë°ì´í„°x) + íƒœê·¸ê°€ 3ê°œ ì´ìƒì¼ ë•Œ + ì¬ì‹œë„ ë "ì˜¤ë¥˜" ì €ì¥
'''