# -*- coding: utf-8 -*-

import os
import time
import pandas as pd
from queue import Queue
from threading import Thread, Lock
from dotenv import load_dotenv
from groq import Groq

start_time = time.time()

# API í‚¤ ë¡œë”©
load_dotenv()
api_keys = [
    os.getenv("API_KEY_1"),
    os.getenv("API_KEY_2"),
    os.getenv("API_KEY_3"),
    os.getenv("API_KEY_4"),
]

clients = [Groq(api_key=k) for k in api_keys]

model_list = [
    "deepseek-r1-distill-llama-70b",
    "deepseek-r1-distill-qwen-32b",
    "gemma2-9b-it",
    "llama-3.1-8b-instant",
    "llama-3.2-11b-vision-preview",
    "llama-3.2-1b-preview",
    "llama-3.2-3b-preview",
    "llama-3.2-90b-vision-preview",
    "llama-3.3-70b-specdec",
    "llama-3.3-70b-versatile",
    "llama3-70b-8192",
    "llama3-8b-8192",
    "mistral-saba-24b",
    "qwen-2.5-32b",
    "qwen-2.5-coder-32b",
    "qwen-qwq-32b"
]

# íƒœê·¸ ëª©ë¡
raw_tag_list = """íŒíƒ€ì§€
SF
ë¯¸ìŠ¤í„°ë¦¬
ìŠ¤ë¦´ëŸ¬
ê³µí¬
ë¡œë§¨ìŠ¤
ì—­ì‚¬ì†Œì„¤
ëª¨í—˜
ì½”ë¯¸ë””
ë“œë¼ë§ˆ
ê°ë™ì ì¸
ìž”ìž”í•œ
ê¸´ìž¥ê° ìžˆëŠ”
ìš°ìš¸í•œ
ìœ ë¨¸ëŸ¬ìŠ¤í•œ
ì–´ë‘ìš´
ë°ê³  ê¸ì •ì 
ì² í•™ì 
ì—­ë™ì ì¸
ëª½í™˜ì ì¸
ì—­ì„¤ì ì¸
ìž”í˜¹í•œ
í™©í™€í•œ
ë¶ˆì•ˆê°ì„ ì¡°ì„±í•˜ëŠ”
ì‚¬íšŒ ë¹„íŒì 
ë¶ˆí‰ë“±
ì  ë” ë¬¸ì œ
ì „ìŸê³¼ í‰í™”
ìš´ëª…ê³¼ ìžìœ ì˜ì§€
ë„ë•ì  ë”œë ˆë§ˆ
í˜ëª…ê³¼ ì €í•­
í™˜ê²½ê³¼ ìƒíƒœ
ì˜ë£Œ ë° ë°”ì´ì˜¤í…Œí¬
ì™¸êµì™€ ì •ì¹˜ ìŒëª¨
ê¶Œë ¥ê³¼ ë¶€íŒ¨
ë…¸ë™ê³¼ ê³„ê¸‰íˆ¬ìŸ
ì´ë¯¼ê³¼ ì •ì²´ì„±
ë¬¸í™” ì¶©ëŒ
ë¬´ì •ë¶€ì£¼ì˜
ì „í†µê³¼ í˜ì‹ 
ì¸ê³µì§€ëŠ¥ê³¼ ì •ë³´í™”
ì„±ìž¥ ì´ì•¼ê¸°
íŠ¸ë¼ìš°ë§ˆì™€ ì¹˜ìœ 
ìš°ì •ê³¼ ë™ë£Œì• 
ì¢…êµì Â·ì˜ì  ìš”ì†Œ
ë³µìˆ˜ì™€ ì •ì˜
ì •ì²´ì„± íƒìƒ‰
ë‚´ë©´ íƒêµ¬
ê¸°ì–µê³¼ ì‹œê°„
ì´ì¤‘ì„±
ê¸ˆê¸°ì™€ ë°˜í•­
ìƒëª…ê³¼ ì£½ìŒ
ìš•ë§ê³¼ íƒ€ë½
ìž¬ë‚œÂ·ì„œë°”ì´ë²Œ
ì˜ì‹ì˜ íë¦„
ë¯¸ì™„ì˜ ì´ì•¼ê¸°
ì‹¤í—˜ì  ë¬¸ì²´
í˜•ì‹ íŒŒê´´ì 
ë…íŠ¹í•œ ì„œìˆ  ë°©ì‹
ë””ìŠ¤í† í”¼ì•„
ìœ í† í”¼ì•„
í¬ìŠ¤íŠ¸ ì•„í¬ì¹¼ë¦½ìŠ¤
ì‚¬ì´ë²„íŽ‘í¬
ë‹¤ì¤‘ ìš°ì£¼
ì‹œê°„ ì—¬í–‰
ì´ˆí˜„ì‹¤ì  ê³µê°„
ë¯¸ì§€ì˜ ì˜ì—­ íƒí—˜
ì´ì„¸ê³„
ì‹ í™”ì  ì„¸ê³„
ê°€ìƒ í˜„ì‹¤
ê¸°í›„ ë³€í™” ì„¸ê³„"""

tag_candidates = [t.strip() for t in raw_tag_list.strip().splitlines() if t.strip()]

def generate_prompt(text):
    prompt = """
    ë‹¹ì‹ ì€ ìˆ˜ì²œ ê¶Œì˜ ë¬¸í•™ ìž‘í’ˆì„ ë¶„ì„í•´ ì˜¨ ë² í…Œëž‘ ë¬¸í•™ í‰ë¡ ê°€ìž…ë‹ˆë‹¤.  
    ì§€ê¸ˆë¶€í„° ì•„ëž˜ ì±…ì˜ ì„œí‰ ë˜ëŠ” ì†Œê°œê¸€ì„ ê¸°ë°˜ìœ¼ë¡œ, ì´ ì±…ì˜ ì •ì²´ì„±ì„ ê°€ìž¥ ìž˜ ë“œëŸ¬ë‚´ëŠ” íƒœê·¸ë¥¼ ê³ ë¥´ì„¸ìš”.

    íƒœê¹… ì „ ë°˜ë“œì‹œ ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ê³ í•˜ê³  íŒë‹¨í•˜ì„¸ìš”:

    [1ë‹¨ê³„] ì´ ì±…ì´ ë‹¤ë£¨ëŠ” ì¤‘ì‹¬ ì£¼ì œë‚˜ ë©”ì‹œì§€ëŠ” ë¬´ì—‡ì¸ê°€ìš”?
    [2ë‹¨ê³„] ì´ì•¼ê¸°ì˜ ë¶„ìœ„ê¸°(ì˜ˆ: ë”°ëœ»í•¨, ì–´ë‘ì›€, ê¸´ìž¥ê° ë“±)ëŠ” ì–´ë–¤ê°€ìš”?
    [3ë‹¨ê³„] ê°ˆë“±, ë¬¸ì œì˜ì‹, ì‚¬íšŒì  ë©”ì‹œì§€ê°€ ë“œëŸ¬ë‚˜ëŠ” ì§€ì ì´ ìžˆë‹¤ë©´ ë¬´ì—‡ì¸ê°€ìš”?
    [4ë‹¨ê³„] ìœ„ ë¶„ì„ì„ ì¢…í•©í•´, ì•„ëž˜ ì œê³µëœ íƒœê·¸ ëª©ë¡ ì¤‘ì—ì„œ ì±…ì„ ê°€ìž¥ ì •í™•ížˆ í‘œí˜„í•˜ëŠ” íƒœê·¸ë¥¼ 3~5ê°œ ì„ íƒí•˜ì„¸ìš”.

    ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ì¡°ê±´:
    - íƒœê·¸ëŠ” ì•„ëž˜ ì œê³µëœ ëª©ë¡ ì¤‘ì—ì„œë§Œ ì„ íƒ
    - ë°˜ë“œì‹œ 3ê°œ ì´ìƒ, 5ê°œ ì´í•˜
    - ì¤‘ë³µ ì—†ì´, ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„ëœ í•œ ì¤„ë¡œ ì¶œë ¥
    - ì„¤ëª…, í•´ì„, ë¶€ì—° ì„¤ëª… ì—†ì´ íƒœê·¸ë§Œ ì¶œë ¥
    """
    return f"{prompt}\n\n{text}\n\n{raw_tag_list}"

def extract_valid_tags(text):
    raw_tags = [tag.strip() for tag in text.split(",") if tag.strip()]
    seen = set()
    unique_valid_tags = []
    for tag in raw_tags:
        if tag in tag_candidates and tag not in seen:
            seen.add(tag)
            unique_valid_tags.append(tag)
    return unique_valid_tags

results = {}
token_cooldown = {}
all_combos = [(m, i) for m in model_list for i in range(len(clients))]
combo_index = 0
combo_lock = Lock()
processed_isbns_lock = Lock()
task_queue = Queue()

tagged_file = "revise_book_test_tagged.csv"
if os.path.exists(tagged_file):
    existing_df = pd.read_csv(tagged_file)
    processed_isbns = set(existing_df["isbn"].dropna().astype(str).tolist())
else:
    existing_df = pd.DataFrame(columns=["isbn", "AI_íƒœê·¸"])
    processed_isbns = set()

max_retries = 5

def model_worker():
    global combo_index
    while True:
        item = task_queue.get()
        if item is None:
            break

        idx, isbn, title, review_text, intro, retry_count = item

        with processed_isbns_lock:
            if isbn in processed_isbns:
                task_queue.task_done()
                continue

        # ì¡°ê±´ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ ìž…ë ¥
        if len(review_text.strip()) > 100:
            input_text = review_text
        else:
            input_text = intro

        prompt = generate_prompt(input_text)

        with combo_lock:
            combo = all_combos[combo_index % len(all_combos)]
            combo_index += 1

        model, client_idx = combo
        client = clients[client_idx]
        cooldown_key = (model, client_idx)

        now = time.time()
        last_used = token_cooldown.get(cooldown_key, 0)
        wait_time = max(0, 4 - (now - last_used))
        if wait_time > 0:
            time.sleep(wait_time)

        try:
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ë¬¸í•™ ì „ë¬¸ê°€ë¡œì„œ í•œêµ­ì–´ë¡œ ë‹µí•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt},
                ],
                temperature=0.2,
                max_completion_tokens=300,
                top_p=1,
                stream=False,
                timeout=10
            )
            token_cooldown[cooldown_key] = time.time()
            content = response.choices[0].message.content.strip()
            tags = extract_valid_tags(content)

            if len(tags) < 3:
                print(f"âš ï¸ [{idx+1}] {title} â†’ íƒœê·¸ ë¶€ì¡± â†’ ìž¬ì‹œë„ {retry_count+1}/{max_retries}")
                if retry_count + 1 < max_retries:
                    task_queue.put((idx, isbn, title, review_text, intro, retry_count+1))
                else:
                    tag_str = "ì˜¤ë¥˜"
                    new_row = pd.DataFrame([{"isbn": isbn, "AI_íƒœê·¸": tag_str}])
                    write_header = not os.path.exists(tagged_file) or os.path.getsize(tagged_file) == 0
                    new_row.to_csv(tagged_file, mode="a", header=write_header, index=False, encoding="utf-8-sig")
                    with processed_isbns_lock:
                        processed_isbns.add(isbn)
                    print(f"ðŸ“Œ ì €ìž¥ëœ ISBN: {isbn} / íƒœê·¸: ì˜¤ë¥˜")
            else:
                tag_str = ", ".join(tags)
                print(f"âœ… [{idx+1}] {title} â†’ {tags} ({model}, API_KEY_{client_idx+1})")
                new_row = pd.DataFrame([{"isbn": isbn, "AI_íƒœê·¸": tag_str}])
                write_header = not os.path.exists(tagged_file) or os.path.getsize(tagged_file) == 0
                new_row.to_csv(tagged_file, mode="a", header=write_header, index=False, encoding="utf-8-sig")
                with processed_isbns_lock:
                    processed_isbns.add(isbn)
                print(f"ðŸ“Œ ì €ìž¥ëœ ISBN: {isbn} / íƒœê·¸: {tag_str}")

        except Exception as e:
            print(f"âŒ [{idx+1}] {title} ì—ëŸ¬: {e} (API_KEY_{client_idx+1})")
            if retry_count + 1 < max_retries:
                task_queue.put((idx, isbn, title, review_text, intro, retry_count+1))

        task_queue.task_done()

# âœ… CSV ë¡œë“œ ë° ì»¬ëŸ¼ ì†Œë¬¸ìží™”
df = pd.read_csv("yes24_steadyseller.csv", on_bad_lines='skip', encoding="utf-8")
df.columns = [col.lower() for col in df.columns]

# âœ… task_queueì— ë„£ê¸° ì „ì— intro + reviewê°€ ë‘˜ ë‹¤ ì§§ìœ¼ë©´ ì œì™¸
for idx, row in df.iterrows():
    isbn = str(row.get("isbn", "")).strip()
    if not isbn or isbn.lower() == "nan" or isbn in processed_isbns:
        continue

    title = row.get("title", "")
    review = str(row.get("publisher_review", "")).strip()
    intro = str(row.get("intro", "")).strip()

    if len(review) <= 50 and len(intro) <= 50:
        continue  # âœ… ë‘˜ ë‹¤ ì§§ìœ¼ë©´ íƒœê·¸ ìƒëžµ

    task_queue.put((idx, isbn, title, review, intro, 0))

# âœ… ì“°ë ˆë“œ ì‹¤í–‰
threads = []
num_threads = len(model_list) * len(clients) // 2
for _ in range(num_threads):
    t = Thread(target=model_worker)
    t.start()
    threads.append(t)

# âœ… ìž‘ì—… ëŒ€ê¸°
task_queue.join()
for _ in threads:
    task_queue.put(None)
for t in threads:
    t.join()

end_time = time.time()
print(f"\nâœ… ì„œí‰ íƒœê·¸ ì¶”ì¶œ ì™„ë£Œ â†’ '{tagged_file}'ì— ì €ìž¥ë¨!")
print(f"â±ï¸ ì „ì²´ ì†Œìš” ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
